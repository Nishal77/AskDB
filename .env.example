# ============================================
# AskYourDatabase - Environment Variables
# ============================================
# Copy this file to .env and fill in your actual values
# Command: cp .env.example .env

# ============================================
# ðŸš¨ REQUIRED VARIABLES
# ============================================

# OpenRouter API Key (REQUIRED)
# Get from: https://openrouter.ai/keys
# Format: sk-or-v1-...
OPENROUTER_API_KEY=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

# Database URL for Prisma (REQUIRED)
# Format: postgresql://USER:PASSWORD@HOST:PORT/DATABASE?schema=SCHEMA
# For Docker: postgresql://postgres:postgres@localhost:5432/askyourdatabase?schema=public
DATABASE_URL="postgresql://postgres:postgres@localhost:5432/askyourdatabase?schema=public"

# JWT Secret Key (REQUIRED)
# Generate with: openssl rand -base64 32
# Must be at least 32 characters long
JWT_SECRET=your-super-secret-jwt-key-change-in-production-min-32-chars

# ============================================
# ðŸ”§ OPTIONAL VARIABLES (with defaults)
# ============================================

# Server Configuration
PORT=3000
NODE_ENV=development

# JWT Configuration
JWT_EXPIRES_IN=7d

# OpenRouter Model Configuration
# Options: openai/gpt-4-turbo-preview, openai/gpt-4, anthropic/claude-3-opus, etc.
# See: https://openrouter.ai/models
OPENROUTER_MODEL=openai/gpt-4-turbo-preview
OPENROUTER_EMBEDDING_MODEL=openai/text-embedding-3-small

# Vector Database Configuration
# (Can be same as main database if using PostgreSQL with pgvector)
VECTOR_DB_HOST=localhost
VECTOR_DB_PORT=5432
VECTOR_DB_DATABASE=askyourdatabase
VECTOR_DB_USER=postgres
VECTOR_DB_PASSWORD=postgres

# Application Configuration
APP_NAME=AskYourDatabase
APP_VERSION=1.0.0

# CORS Configuration
FRONTEND_URL=http://localhost:3001

# Web Configuration
NEXT_PUBLIC_API_URL=http://localhost:3000/api/v1

# Docker Configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=askyourdatabase
POSTGRES_PORT=5432
API_PORT=3000
WEB_PORT=3001

# LLM Fallback Models Configuration
# The system will automatically try these models in order if the primary model fails
# (e.g., rate limits, insufficient credits). Models are tried sequentially until one succeeds.
# Format: Comma-separated list of model identifiers
# Free tier models available: tngtech/deepseek-r1t2-chimera:free, qwen/qwen3-coder:free
# Default: Primary model -> tngtech/deepseek-r1t2-chimera:free -> qwen/qwen3-coder:free
OPENROUTER_FALLBACK_MODELS=tngtech/deepseek-r1t2-chimera:free,qwen/qwen3-coder:free
